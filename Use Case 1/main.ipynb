{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ec5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydantic_settings langchain langchain-core langchain-google-genai langchain-qdrant fastembed langchain-community qdrant-client langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c572ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY: str\n",
    "    model_config = SettingsConfigDict(env_file=\".env\")\n",
    "\n",
    "env = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings_2 = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\", google_api_key=env.GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can use FastEmbed for embeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "embeddings_2 = FastEmbedEmbeddings(cache_dir=\"./embedding_cache\", model_name=\"jinaai/jina-embeddings-v2-base-en\")\n",
    "# # https://qdrant.github.io/fastembed/examples/Supported_Models/#supported-text-embedding-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Distance\n",
    "\n",
    "collection_name = \"doctor_packages\"\n",
    "# fastembed\n",
    "dimension = 768 \n",
    "## gemini embedding\n",
    "# dimension = 3072\n",
    "distance = Distance.COSINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c7696",
   "metadata": {},
   "source": [
    "# Create Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mcu.json data\n",
    "import json\n",
    "\n",
    "with open(\"doctors_final.json\", \"r\") as f:\n",
    "    mcu_data = json.load(f)\n",
    "\n",
    "print(mcu_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deeb5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import VectorParams\n",
    "\n",
    "if(client.collection_exists(collection_name=collection_name) == False):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=distance),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b681ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "import uuid\n",
    "i = 0\n",
    "for row in mcu_data:\n",
    "    i += 1\n",
    "          \n",
    "    text = f\"Doctor {row['name']} is a {row['sub_specialization_name_en']} in the field of {row['specialization_name_en']} at {row['hospital_name']}.\"\n",
    "    emb = embeddings_2.embed_query(text)\n",
    "    print(i)\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=str(uuid.uuid4()),  # Generate a unique ID for each point\n",
    "                vector=emb, \n",
    "                payload={\n",
    "                    \"page_content\": text,\n",
    "                    \"metadata\": {\n",
    "                            \"id\": row['id'],\n",
    "                            \"name\": row['name'],\n",
    "                            \"specialization_name\": row['specialization_name'],\n",
    "                            \"sub_specialization_name\": row['sub_specialization_name'],\n",
    "                            \"hospital_name\": row['hospital_name']\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4101842",
   "metadata": {},
   "source": [
    "# Create Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bb1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "def get_retriever():\n",
    "\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings_2,\n",
    "    )\n",
    "    \n",
    "    return vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, List\n",
    "\n",
    "@tool\n",
    "def search_doctors_recommendation(query: Annotated[str, \"search query must contain keywords related to doctor packages\"]) -> List[str]:\n",
    "    \"\"\"Search for doctors by name, specialization, sub specialization, symptom, or hospital name.\"\"\"\n",
    "    retriever = get_retriever()\n",
    "    results = retriever.invoke(query, k=10)\n",
    "    return [result.page_content for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f77e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_doctors_recommendation(\"psychologist for anxiety in yogyakarta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0dc87",
   "metadata": {},
   "source": [
    "# Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the Google Gemini API\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=env.GOOGLE_API_KEY,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that provides information about doctor information from various hospitals and city but mainly from Siloam Hospital Group.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"I'm currently feeling severe anxiety, is there any doctor for my condition?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33894fe",
   "metadata": {},
   "source": [
    "# Workflow for agent to use tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[str]\n",
    "    search: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb95d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(state: State):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are an customer service and concierge for giving doctor recommendation.\n",
    "                You will provide one or more doctors recommendation based on the question.\n",
    "                The keywords should be relevant to the doctors data available at Siloam hospitals group.\n",
    "                Try not to provide any other information.\n",
    "                If the question already contains keywords, you can return them as is.\n",
    "                Only return doctor name, specialization, and hospital name in english.\n",
    "\n",
    "                Based on the user's question, extract the most relevant medical specialization or symptom. \n",
    "                The keywords should be in English. \n",
    "                For example, if the user asks 'my stomach hurts', a good keyword is 'Gastroenterology'. If they ask 'I need a doctor for my child', a good keyword is 'Pediatrics'. \n",
    "                Only return the keyword(s).\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"question\": state[\"question\"]})\n",
    "    return {\"search\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = search_doctors_recommendation(state[\"search\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f675a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: State):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You provide doctor recommendations based on the context provided. \n",
    "                Answer the user's question by suggesting one or more doctors from the list. \n",
    "                Clearly state their name, specialization, and hospital. \n",
    "                Format the response nicely. \n",
    "                doctor list knowledge: \n",
    "                {context}\n",
    "                If no relevant doctors are found in the context, politely say that you couldn't find a specific match but can help with other queries\n",
    "\n",
    "                \n",
    "            \"\"\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    return {\"answer\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([get_context, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"get_context\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\n",
    "\t\"question\": \"I'm feeling very stressed and anxious lately, any doctor for my condition?\",\n",
    "\t\"context\": [],\n",
    "\t\"search\": \"\",\n",
    "\t\"answer\": \"\"\n",
    "})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
